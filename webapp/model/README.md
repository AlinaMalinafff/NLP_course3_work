---
tags:
- setfit
- sentence-transformers
- text-classification
- generated_from_setfit_trainer
widget:
- text: 'Критичный вопрос! Мы проводим ежеквартальный аудит: проверяем, чтобы ИИ не
    дискриминировал по полу, возрасту или образованию. Например, выяснилось, что одна
    модель недооценивала кандидатов из небольших городов — пришлось переобучать на
    расширенной выборке. Прозрачность — ключевой принцип.'
- text: 'Чтобы контролировать качество изменений, я создавал четкие критерии для каждой
    задачи. Каждый процесс и изменение в нем фиксировались в виде чек-листов и контрольных
    точек, которые служили для проверки корректности выполнения. После внедрения изменений
    проводился мониторинг первых результатов, и в случае возникновения проблем оперативно
    устранялись недочеты.

    Кроме того, я часто проводил аудиты и проверки на местах, общаясь с теми, кто
    непосредственно работает с новыми процессами. Это позволяло быстро выявлять проблемы
    и корректировать их в реальном времени.'
- text: 'Да, я понимаю, здесь немножко другая схема: ожидается, что ты на середине
    последнего курса уже договариваешься с компанией, и тебя берут на стажировку.
    И ты хотя бы полгода уже стажируешься, и компания они именно под себя подстраивает
    сотрудника. Потом, конечно, могут быть проблемы для сотрудника, что ему сложно
    будет найти работу, особенно если это не какой-то конкретный навык, а обычная
    офисная работа. Этого в сфере айти и дизайна меньше, и ценятся все-таки люди с
    опытом.'
- text: Да, потому что, конечно, и самому же приятный, когда люди что - то вот запоминают.
    Ты там сказал где - то как - то в разговоре, а человек это помнить, и спустя -года
    после этого тебе подарил.
- text: 'Эффективность моей работы оценивалась по тому, как быстро и качественно удается
    внедрить предложенные изменения и какие результаты это приносит. Мы использовали
    метрики, такие как время выполнения операций, уровень дефектности продукции и
    удовлетворенность сотрудников после изменений. Также важным показателем была экономия
    времени и затрат. Например, если мне удавалось сократить время на сборку деталей
    или уменьшить простои оборудования, это становилось хорошим индикатором успешности
    изменений.

    Процесс оценки был цикличным: после каждого внедрения изменений мы проводили ретроспективу,
    чтобы выявить, что сработало, а что нужно было бы сделать по-другому. Это помогало
    корректировать подход и улучшать процессы на каждом этапе.'
metrics:
- accuracy
pipeline_tag: text-classification
library_name: setfit
inference: true
base_model: sentence-transformers/paraphrase-MiniLM-L3-v2
---

# SetFit with sentence-transformers/paraphrase-MiniLM-L3-v2

This is a [SetFit](https://github.com/huggingface/setfit) model that can be used for Text Classification. This SetFit model uses [sentence-transformers/paraphrase-MiniLM-L3-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L3-v2) as the Sentence Transformer embedding model. A [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) instance is used for classification.

The model has been trained using an efficient few-shot learning technique that involves:

1. Fine-tuning a [Sentence Transformer](https://www.sbert.net) with contrastive learning.
2. Training a classification head with features from the fine-tuned Sentence Transformer.

## Model Details

### Model Description
- **Model Type:** SetFit
- **Sentence Transformer body:** [sentence-transformers/paraphrase-MiniLM-L3-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L3-v2)
- **Classification head:** a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) instance
- **Maximum Sequence Length:** 128 tokens
- **Number of Classes:** 3 classes
<!-- - **Training Dataset:** [Unknown](https://huggingface.co/datasets/unknown) -->
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Repository:** [SetFit on GitHub](https://github.com/huggingface/setfit)
- **Paper:** [Efficient Few-Shot Learning Without Prompts](https://arxiv.org/abs/2209.11055)
- **Blogpost:** [SetFit: Efficient Few-Shot Learning Without Prompts](https://huggingface.co/blog/setfit)

### Model Labels
| Label       | Examples                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
|:------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Процесс     | <ul><li>'Вот, например, я наблюдала, как моя сэмпай, днем она, может, не очень сфокусирована, может взять себе кофе, поболтать с другой, с ее сэмпаем, у нее может быть встреча с клиентами, созвон. Но потом она вечером сидит там до девяти, до восьми, и это считается хорошо, что она старается. …Да, так о чем я говорила?'</li><li>'Я занимал позицию директора по -сервису в e - commerce - компании. Основной задачей было обеспечить рост выручки через цифровые каналы. За полтора года мы увеличили продажи на 87 %, сократили стоимость привлечения клиента на 22 % и выходить на новые рынки — в частности, Беларусь и Узбекистан.\nОрганизация процесса была подчинена целям. Я выстраивал квартальные цели по выручке, ROMI и LTV. Мы отслеживали динамику регулярно, и если показатели не росли — моментально вносили коррективы. Вся структура подчинялась схематизй « что мы хотим достичь и как быстро это измеримо ».'</li><li>'Ну и лицемерие, да, тоже. Ты думаешь, вот я ему сейчас что-то рассказываю, потом он это как-то может по-своему интерпретировать и тебя будет воспринимать как какого-то, ну, не очень приятного человека. То есть они как-то могут вот это по своему каждый раз переворачивать. Вот.'</li></ul> |
| Результат   | <ul><li>'Ну, примерно, да.'</li><li>'Я считаюсь как руководителем этих…'</li><li>'Пример какой-то привести?'</li></ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| Нейтральный | <ul><li>'Мы не просто доставляем еду — мы используем ИИ для персонализации меню. Алгоритм анализирует предпочтения пользователя и предлагает блюда, которые он с высокой вероятностью закажет снова. Это снижает процент отмен заказов на 30%.'</li><li>'С руководством, ну начальник иногда приходил на работу, иногда нет.'</li><li>'Только рядом с вольнослушатель или коворкингами. Наша аудитория — университет и фрилансеры, которые ценят атмосферу.'</li></ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

## Uses

### Direct Use for Inference

First install the SetFit library:

```bash
pip install setfit
```

Then you can load this model and run inference.

```python
from setfit import SetFitModel

# Download from the 🤗 Hub
model = SetFitModel.from_pretrained("setfit_model_id")
# Run inference
preds = model("Да, потому что, конечно, и самому же приятный, когда люди что - то вот запоминают. Ты там сказал где - то как - то в разговоре, а человек это помнить, и спустя -года после этого тебе подарил.")
```

<!--
### Downstream Use

*List how someone could finetune this model on their own dataset.*
-->

<!--
### Out-of-Scope Use

*List how the model may foreseeably be misused and address what users ought not to do with the model.*
-->

<!--
## Bias, Risks and Limitations

*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*
-->

<!--
### Recommendations

*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*
-->

## Training Details

### Training Set Metrics
| Training set | Min | Median  | Max |
|:-------------|:----|:--------|:----|
| Word count   | 3   | 81.7857 | 628 |

| Label       | Training Sample Count |
|:------------|:----------------------|
| Нейтральный | 14                    |
| Процесс     | 292                   |
| Результат   | 44                    |

### Training Hyperparameters
- batch_size: (16, 2)
- num_epochs: (1, 16)
- max_steps: -1
- sampling_strategy: oversampling
- body_learning_rate: (2e-05, 1e-05)
- head_learning_rate: 0.01
- loss: CosineSimilarityLoss
- distance_metric: cosine_distance
- margin: 0.25
- end_to_end: False
- use_amp: False
- warmup_proportion: 0.1
- l2_weight: 0.01
- seed: 42
- eval_max_steps: -1
- load_best_model_at_end: False

### Training Results
| Epoch  | Step | Training Loss | Validation Loss |
|:------:|:----:|:-------------:|:---------------:|
| 0.0002 | 1    | 0.2416        | -               |
| 0.0091 | 50   | 0.3648        | -               |
| 0.0182 | 100  | 0.2967        | -               |
| 0.0273 | 150  | 0.2332        | -               |
| 0.0365 | 200  | 0.2214        | -               |
| 0.0456 | 250  | 0.2201        | -               |
| 0.0547 | 300  | 0.1994        | -               |
| 0.0638 | 350  | 0.203         | -               |
| 0.0729 | 400  | 0.1927        | -               |
| 0.0820 | 450  | 0.1744        | -               |
| 0.0912 | 500  | 0.161         | -               |
| 0.1003 | 550  | 0.1594        | -               |
| 0.1094 | 600  | 0.1299        | -               |
| 0.1185 | 650  | 0.1264        | -               |
| 0.1276 | 700  | 0.1043        | -               |
| 0.1367 | 750  | 0.0855        | -               |
| 0.1459 | 800  | 0.0759        | -               |
| 0.1550 | 850  | 0.0563        | -               |
| 0.1641 | 900  | 0.0634        | -               |
| 0.1732 | 950  | 0.0588        | -               |
| 0.1823 | 1000 | 0.0423        | -               |
| 0.1914 | 1050 | 0.0474        | -               |
| 0.2005 | 1100 | 0.0442        | -               |
| 0.2097 | 1150 | 0.0369        | -               |
| 0.2188 | 1200 | 0.0363        | -               |
| 0.2279 | 1250 | 0.0352        | -               |
| 0.2370 | 1300 | 0.0276        | -               |
| 0.2461 | 1350 | 0.0297        | -               |
| 0.2552 | 1400 | 0.0279        | -               |
| 0.2644 | 1450 | 0.0205        | -               |
| 0.2735 | 1500 | 0.0192        | -               |
| 0.2826 | 1550 | 0.0191        | -               |
| 0.2917 | 1600 | 0.0171        | -               |
| 0.3008 | 1650 | 0.013         | -               |
| 0.3099 | 1700 | 0.0159        | -               |
| 0.3191 | 1750 | 0.0153        | -               |
| 0.3282 | 1800 | 0.0154        | -               |
| 0.3373 | 1850 | 0.0112        | -               |
| 0.3464 | 1900 | 0.0126        | -               |
| 0.3555 | 1950 | 0.0126        | -               |
| 0.3646 | 2000 | 0.0084        | -               |
| 0.3737 | 2050 | 0.0127        | -               |
| 0.3829 | 2100 | 0.0145        | -               |
| 0.3920 | 2150 | 0.0083        | -               |
| 0.4011 | 2200 | 0.0082        | -               |
| 0.4102 | 2250 | 0.0117        | -               |
| 0.4193 | 2300 | 0.0097        | -               |
| 0.4284 | 2350 | 0.0089        | -               |
| 0.4376 | 2400 | 0.0071        | -               |
| 0.4467 | 2450 | 0.0062        | -               |
| 0.4558 | 2500 | 0.0052        | -               |
| 0.4649 | 2550 | 0.0066        | -               |
| 0.4740 | 2600 | 0.0057        | -               |
| 0.4831 | 2650 | 0.0071        | -               |
| 0.4923 | 2700 | 0.0048        | -               |
| 0.5014 | 2750 | 0.0076        | -               |
| 0.5105 | 2800 | 0.0044        | -               |
| 0.5196 | 2850 | 0.005         | -               |
| 0.5287 | 2900 | 0.0045        | -               |
| 0.5378 | 2950 | 0.0055        | -               |
| 0.5469 | 3000 | 0.0035        | -               |
| 0.5561 | 3050 | 0.0085        | -               |
| 0.5652 | 3100 | 0.0054        | -               |
| 0.5743 | 3150 | 0.0026        | -               |
| 0.5834 | 3200 | 0.0044        | -               |
| 0.5925 | 3250 | 0.0031        | -               |
| 0.6016 | 3300 | 0.0055        | -               |
| 0.6108 | 3350 | 0.0048        | -               |
| 0.6199 | 3400 | 0.0073        | -               |
| 0.6290 | 3450 | 0.0025        | -               |
| 0.6381 | 3500 | 0.0032        | -               |
| 0.6472 | 3550 | 0.0056        | -               |
| 0.6563 | 3600 | 0.002         | -               |
| 0.6655 | 3650 | 0.0048        | -               |
| 0.6746 | 3700 | 0.0024        | -               |
| 0.6837 | 3750 | 0.0044        | -               |
| 0.6928 | 3800 | 0.0013        | -               |
| 0.7019 | 3850 | 0.0053        | -               |
| 0.7110 | 3900 | 0.0021        | -               |
| 0.7201 | 3950 | 0.0055        | -               |
| 0.7293 | 4000 | 0.0028        | -               |
| 0.7384 | 4050 | 0.0017        | -               |
| 0.7475 | 4100 | 0.002         | -               |
| 0.7566 | 4150 | 0.0045        | -               |
| 0.7657 | 4200 | 0.004         | -               |
| 0.7748 | 4250 | 0.0027        | -               |
| 0.7840 | 4300 | 0.0028        | -               |
| 0.7931 | 4350 | 0.0039        | -               |
| 0.8022 | 4400 | 0.0012        | -               |
| 0.8113 | 4450 | 0.0026        | -               |
| 0.8204 | 4500 | 0.0034        | -               |
| 0.8295 | 4550 | 0.0014        | -               |
| 0.8387 | 4600 | 0.0041        | -               |
| 0.8478 | 4650 | 0.001         | -               |
| 0.8569 | 4700 | 0.0026        | -               |
| 0.8660 | 4750 | 0.0028        | -               |
| 0.8751 | 4800 | 0.0033        | -               |
| 0.8842 | 4850 | 0.0029        | -               |
| 0.8933 | 4900 | 0.0012        | -               |
| 0.9025 | 4950 | 0.0014        | -               |
| 0.9116 | 5000 | 0.0024        | -               |
| 0.9207 | 5050 | 0.001         | -               |
| 0.9298 | 5100 | 0.0017        | -               |
| 0.9389 | 5150 | 0.0012        | -               |
| 0.9480 | 5200 | 0.0025        | -               |
| 0.9572 | 5250 | 0.0031        | -               |
| 0.9663 | 5300 | 0.0009        | -               |
| 0.9754 | 5350 | 0.0025        | -               |
| 0.9845 | 5400 | 0.0019        | -               |
| 0.9936 | 5450 | 0.0031        | -               |

### Framework Versions
- Python: 3.11.12
- SetFit: 1.1.2
- Sentence Transformers: 4.1.0
- Transformers: 4.52.3
- PyTorch: 2.6.0+cu124
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citation

### BibTeX
```bibtex
@article{https://doi.org/10.48550/arxiv.2209.11055,
    doi = {10.48550/ARXIV.2209.11055},
    url = {https://arxiv.org/abs/2209.11055},
    author = {Tunstall, Lewis and Reimers, Nils and Jo, Unso Eun Seo and Bates, Luke and Korat, Daniel and Wasserblat, Moshe and Pereg, Oren},
    keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Efficient Few-Shot Learning Without Prompts},
    publisher = {arXiv},
    year = {2022},
    copyright = {Creative Commons Attribution 4.0 International}
}
```

<!--
## Glossary

*Clearly define terms in order to be accessible across audiences.*
-->

<!--
## Model Card Authors

*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*
-->

<!--
## Model Card Contact

*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*
-->